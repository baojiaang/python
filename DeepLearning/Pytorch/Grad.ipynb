{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2    # 每个元素后面都加上\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z,out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x000001FA2006D148>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "  # backprop\n",
    "out.backward()\n",
    "print(x.grad)     #  对 x 求 梯度  d(out)/dx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-203.1638,  751.3751, -790.2905], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 4])\n",
      "torch.Size([10, 4, 5])\n",
      "tensor([[[-8.4431e-01,  2.4942e+00,  1.5517e+00, -3.2884e+00, -7.5976e-01],\n",
      "         [ 7.3478e-02, -9.2005e-01, -1.7234e+00,  1.7148e+00,  1.5269e+00],\n",
      "         [-4.9098e-01,  1.8992e+00,  8.5160e-02,  9.1001e-01,  6.0781e-01]],\n",
      "\n",
      "        [[-1.5911e+00, -5.5965e-01,  8.0110e-01,  1.7565e+00,  7.7422e-01],\n",
      "         [-2.2625e+00, -4.6642e+00,  1.3780e+00, -2.7596e+00,  2.1596e+00],\n",
      "         [-2.1674e+00, -2.2215e-01,  8.6849e-01,  1.8657e+00,  3.3883e+00]],\n",
      "\n",
      "        [[ 6.7001e+00,  1.2981e+00,  4.4339e+00, -1.0102e+00, -3.4357e+00],\n",
      "         [-1.1019e+00, -1.1270e+00, -4.3272e-01,  3.4398e-01,  1.9397e+00],\n",
      "         [-9.2975e-01,  1.8256e+00, -3.6584e-01, -1.2278e+00, -3.2544e+00]],\n",
      "\n",
      "        [[ 8.4463e-01,  7.4221e-01,  1.2989e+00,  3.6386e-01, -6.5071e-01],\n",
      "         [-1.3381e+00, -1.3566e+00,  2.3092e-01,  8.0266e-01,  1.9595e-03],\n",
      "         [-1.4993e+00,  6.8853e-01,  1.4760e+00,  1.0831e+00, -1.8837e-01]],\n",
      "\n",
      "        [[-2.4909e+00, -6.8046e+00, -6.6621e-01,  7.9883e+00,  4.8255e-01],\n",
      "         [ 1.4432e-01,  9.7894e-02,  4.6591e-01, -5.1053e-01,  9.2302e-01],\n",
      "         [ 2.2209e+00, -3.5165e-01, -4.7617e+00,  4.9809e+00,  4.1390e+00]],\n",
      "\n",
      "        [[ 2.1312e+00,  1.5683e+00, -1.6241e+00, -2.2457e+00,  2.3873e-01],\n",
      "         [-2.1237e+00,  2.7162e+00, -2.3269e+00,  1.6912e-01, -2.3783e+00],\n",
      "         [ 2.9223e+00, -1.5318e+00,  4.8750e-01, -1.4912e+00,  1.5783e+00]],\n",
      "\n",
      "        [[-8.7988e-02,  1.6023e-01,  1.6172e-01, -3.3463e-01, -3.8017e-01],\n",
      "         [-9.2601e-01, -1.7714e+00, -2.1816e+00,  3.3632e+00, -1.1850e+00],\n",
      "         [ 9.3278e-01, -8.6322e-01,  4.3421e-01, -1.2188e+00,  8.2828e-01]],\n",
      "\n",
      "        [[ 5.4739e+00, -1.3061e-01, -1.7951e+00, -2.5477e+00, -3.0279e+00],\n",
      "         [-1.8881e+00, -2.7538e-01, -6.8967e-01,  1.6122e+00,  3.6479e-01],\n",
      "         [ 1.2019e-01, -2.8702e-01,  1.6276e-01, -1.3579e-01, -1.1179e+00]],\n",
      "\n",
      "        [[-3.5055e+00, -1.3808e+00,  2.9406e+00,  4.9683e-01, -2.3370e+00],\n",
      "         [-7.8538e-01, -1.1616e+00, -1.8706e-01, -4.7660e-01,  1.3246e+00],\n",
      "         [-4.7794e-02,  1.3415e-01,  1.8711e+00,  6.8408e-01,  1.7195e+00]],\n",
      "\n",
      "        [[ 1.1662e+00, -8.1204e-01, -2.7265e+00, -1.0254e+00, -1.4258e+00],\n",
      "         [ 8.9429e-01, -1.3130e+00, -4.2920e+00, -7.6456e-01, -3.0801e+00],\n",
      "         [ 1.0871e+00,  4.3433e-01, -1.6356e+00, -1.7023e+00, -1.9202e-01]]],\n",
      "       grad_fn=<BmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "batch1 = torch.randn(10, 3, 4)\n",
    "batch2 = torch.randn(10, 4, 5)\n",
    "batch1.requires_grad_(True)\n",
    "batch2.requires_grad_(True)\n",
    "print(batch1.shape)\n",
    "print(batch2.shape)\n",
    "res = torch.bmm(batch1, batch2)\n",
    "print(res)\n",
    "# x = torch.tensor([3,3,3])\n",
    "# y = torch.tensor([[1,2,3],[3,4,3]])\n",
    "# print(x.shape)\n",
    "# print(y.shape)\n",
    "# z = torch.mm(x,y)\n",
    "# print(z)\n",
    "grad_tensor = torch.ones(10,3,5)\n",
    "res.backward(grad_tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0757,  0.3318,  0.5485],\n",
      "         [-0.4240, -0.8439,  0.2603],\n",
      "         [-0.0914, -0.1799,  0.6055]],\n",
      "\n",
      "        [[ 0.2746,  0.7052,  0.7522],\n",
      "         [ 1.7225, -0.4954,  0.5483],\n",
      "         [ 0.1778, -0.4291,  2.0804]],\n",
      "\n",
      "        [[ 0.6068, -0.3127, -0.3094],\n",
      "         [ 0.4608, -0.9867,  1.6668],\n",
      "         [ 0.5965,  1.0938, -0.7315]]])\n",
      "tensor([[ 0.5485,  0.2603,  0.6055],\n",
      "        [ 0.7522,  0.5483,  2.0804],\n",
      "        [-0.3094,  1.6668, -0.7315]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,3,3)\n",
    "print(x)\n",
    "x = x[:,:,-1]\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}